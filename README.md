# Code-Review-of-BiomedGPT Based on LLM 
In this repo Provide General Overview how does BiomedGPT Built to tackle Multi-Modalities Input to generate Textual Output relate to BioMedical handle multi-Task such : 

* Classification
* Caption 
* V&Q 
* image filling
* masked language modeling 

<div align="center">
    <img src="assets/modeling.png" width="600" height="350" />
</div>

**Notation**: WE WILL SPLIT OUR REVIEW PAPER AND CODE FOLLOWING SECTION ..

1. [BAKCGROUND](#BAKCGROUND)
2. [PAPER INSGHTS](#PAPERINSGHTS)
3. [BiomedGPT Pipeline](#BiomedGPTPipeline)
5. [ENVIREMNET SETUP](#ENVIREMNETSETUP)
5. [RESULTS](#Results)
5. [CONCLUSION](#CONCLUSION)

### BAKCGROUND

Introducing BiomedGPT (Biomedical Generative Pre-trained Transformer), the paper presents a versatile model tailored for diverse biomedical data and tasks. Leveraging self-supervision on extensive datasets, BiomedGPT exhibits superior performance over leading benchmarks. The study encompasses five tasks and 20 public datasets spanning 15 distinct biomedical modalities, highlighting BiomedGPT's broad applicability. Notably, the authors' innovative multi-modal, multitask pretraining approach showcases effective knowledge transfer to novel data. This contribution marks a significant stride in creating adaptable and comprehensive biomedicine models, offering potential enhancements to healthcare outcomes.
 

### PAPER INSGHTS

we will include the most interesting ideas in the paper the Co-authors discussed and explained in their paper 


